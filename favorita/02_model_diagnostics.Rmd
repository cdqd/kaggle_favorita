---
title: "Gradient Boosting as a time series model"
subtitle: "Favorita Grocery Sales Forecasting"
output:
  html_document:
    df_print: paged
    fig_height: 8
    fig_width: 11
    toc: yes
---

#### Summary of model specifications

Variables used in training:

- Means over the most recent 3, 14, 30, 60, 140 days.
- Day of week means over the most recent 4, 20 day-of-weeks.
- The total number of times the item has been on promotion over the most recent 14, 30, 60, 140 days
- Standard Deviation, and Quantiles from 0 to 1 (incremented by 0.1) for sale numbers over the most recent 30, 60, 140 days
- Standard Deviation, and Quantiles for day of week sales over most recent 20 day-of-weeks.

Quantiles were included as a way to represent the distribution of past sales.

Validation framework:

- 6 blocks of training data were created (with the end dates of each training chunk 1 week apart) and stacked together, creating about 1 million rows of training data and 160 variables.
- A single validation block was used (2017-07-26 to 2017-08-10); keeping as close to the competition's prediction period/business problem as possible. The weekdays included in the validation period replicate that of the competition's prediction period.
- lightgbm or xgboost was used to tune each of the 16 models for the number of trees, with other parameters chosen heuristically and held fixed.

Analysis will be based on Root Mean Squared Log Error (RMSLE).

```{r include = F}
rm(list = ls())
invisible(gc())
load(".RData")
library(tidyverse)
library(data.table)
library(xgboost)
library(knitr)

theme_set(theme_minimal())

# Load additional mapping data
population <- read_csv("city_population_mapping.csv", na = "", locale = locale(encoding = "ISO-8859-1"))
city_population <- 
  population %>% 
  filter(nchar(code) == 4 | city_municipality == "Puyo")

item_family_2 <- read_csv("item_type_mapping.csv",  na = "")

# Calculate rmsle components
x <- (val_pred[, -(1:2)] - y_val[, -(1:2)])^2
rmsle_components <- cbind(y_val[, 1:2], x)


rmsle_fullinfo <-
  rmsle_components %>% 
  left_join(stores, 
            by = c("store_nbr")) %>%
  left_join(select(items, -class), 
            by = c("item_nbr")) %>% 
  left_join(item_family_2,
            by = c("family")) %>% 
  as.tbl()

overall_rmsle <-
  sqrt(mean(unlist(rmsle_fullinfo[, 3:18])))

# Helper function to summarise rmsle by group for all days of the period
rmsle_summary <- function(first_day, last_day, groupby) {
  # days are labelled from 1 to 16 (slightly different to t0 - t15 naming convention)
  ds <- grep(paste0("^y_", first_day, "$"), names(rmsle_fullinfo))
  de <- grep(paste0("^y_", last_day, "$"), names(rmsle_fullinfo))
  
  return(
    rmsle_fullinfo %>%
    gather_(key = "model", value = "rmsle_component", gather_cols = names(.)[ds:de]) %>% 
  	group_by_(.dots = groupby) %>%
  	summarise(mean_err = sqrt(mean(rmsle_component))) %>% 
    ungroup()
  )
}

# RMSLE by day
results_table <-
	results_table %>%
	mutate(weekend = case_when(
						day %in% c("Sat", "Sun") ~ 1,
						TRUE ~ 0),
				 after_payday = as.numeric(date - as.Date("2017-07-31")),
				 daynum = c(1:16))

# Add features to summarise & analyse by
varimp_all <-
  varimp_all %>%
    mutate(day = lubridate::wday(as.Date("2017-07-26") + bst, label = T),
           stat_group = case_when(
             grepl(pattern = "mean", x = Feature) ~ "mean",
             grepl(pattern = "sd", x = Feature) ~ "standard_dev",
             grepl(pattern = "p[0-9]", x = Feature) ~ "quantile",
             TRUE ~ "sum_promos"),
           dow_feature = case_when(
             grepl(pattern = "dow", x = Feature) ~ 1,
             TRUE ~ 0),
           data_period = str_extract(str_extract(Feature, "(_)([a-z])*[0-9]+"), "[0-9]+"))
```

## RMSLE by day

### Sample actual vs predicted for item/store combinations

```{r}
sample <- c(1, 7500, 80001, 110000)

# 4 sampled item/store combinations
plot_frame <- rbind(
  cbind(y_val[sample, -(1:2)], data.frame(obs = factor(1:4), type = rep("Actual", 4))),
  cbind(val_pred[sample, -(1:2)], data.frame(obs = factor(1:4), type = rep("Predicted", 4)))
  ) %>% 
  gather(key = "date", value = "log_unit_sales", -obs, -type) %>%
  arrange(obs, type) %>% 
  mutate(date = rep(seq.Date(as.Date("2017-07-26"), by = "day", length.out = 16), times = 8))

plot_frame %>% 
  ggplot(aes(x = date, y = log_unit_sales, colour = type)) +
  geom_line() +
  scale_x_date(date_breaks = "1 day") +
  facet_wrap(~obs) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) +
  labs(y = "Log(Sales)", x = NULL, colour = NULL)
```

- Actual sales for specific item/store combinations is volatile.
- GBDT does smooth out predictions a bit (for example, samples 1 and 4). Volatile predictions in 2 and 3 indicate potential overfitting, but this could actually be the historical seasonal trend. 
- Should probably look at whole stores, or prediction accuracy by item, instead.
- Other points to note:
    - GBDT does **not** predict extreme values well.

### Sample actual vs predicted total store sales

```{r}
y_val_sum <- summary_helper(y_val, store_nbr, logscale = T)

val_pred_sum <- summary_helper(val_pred, store_nbr, logscale = T)

# Stores 1 to 4
plot_frame <- rbind(
  cbind(y_val_sum[1:4, ], data.frame(type = rep("Actual", 4))),
  cbind(val_pred_sum[1:4, ], data.frame(type = rep("Predicted", 4)))
) %>% 
  gather(key = "date", value = "log_unit_sales", -store_nbr, -type) %>% 
  arrange(store_nbr, type) %>% 
  mutate(date = rep(seq.Date(as.Date("2017-07-26"), by = "day", length.out = 16), times = 8))

plot_frame %>% 
  ggplot(aes(x = date, y = log_unit_sales, colour = type)) +
  geom_line() +
  scale_x_date(date_breaks = "1 day") +
  facet_wrap(~ store_nbr) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) +
  labs(y = "Log(Sales)", x = NULL, colour = NULL)
```

- Prediction variance by day quite similar across stores.
    - Although this does suggest some prevention of overfitting, it leads to more errors for stores that seem easier to predict (for example store 2). 
- Overall, model predicts log(sales) well, but can consider isolating stores with a relatively constant sales pattern and fitting simpler models for them.

### Total error by prediction day
```{r}
results_table %>% 
  ggplot(aes(x = date, y = val_rmse,  fill = day, colour = day)) +
  geom_point(size = 3, shape = 17) +
  scale_x_date(date_breaks = "1 day") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) +
  labs(y = "RMSLE", x = NULL, colour = NULL, fill = NULL)
```

- As expected, errors increase the further the day is from the training set.
    - Usually **not** a desired feature of time series models (shows heteroskedasticity).
    - Can consider using predictions for earlier days of prediction period to update training data for later days.
- Does not predict end of month trends well - peak errors in early August (post pay-day).
- Errors more **volatile** at the end of the prediction period:
    - This could be an additional effect of moving further away from the training set.
    - Early-month predictions may be poor in general (post pay-day).
  
**Average RMSLE for validation period:** `r round(overall_rmsle, 3)`.

## RMSLE by segment 

### By Geography

```{r}
rmsle_summary(1, 16, c("state", "city")) %>% 
  select(state, city, mean_err) %>% 
  left_join(y = select(city_population, 
                       city_municipality, population),
            by = c("city" = "city_municipality")) %>%
  mutate(overall_compare = (mean_err - overall_rmsle) / overall_rmsle) %>% 
  arrange(mean_err) %>% 
  kable(format = "markdown", digits = 3, 
        col.names = c("State", "City", "RMSLE", "Population", "Relative difference to Overall RMSLE"))
```

- Biggest cities in Ecuador are Quito and Guayaquil; Guayaquil only better predicted by 3% and Quito largely in line with overall RMSLE.
- In contrast, cities at the top are small cities, with improvements of 6-9%. 
    - Could be due to fewer stores, leading to a more homogenous mix of customers for each store. This means buying patterns may be more stable through time, so past sales has high predictive power.
    - However, the worst predicted cities were also small cities.
- No obvious relationship between RMSLE and store location.

### By Store type

```{r}
rmsle_summary(1, 16, "type") %>% 
  select(type, mean_err) %>% 
  mutate(overall_compare = (mean_err - overall_rmsle) / overall_rmsle) %>% 
  arrange(mean_err) %>% 
  kable(format = "markdown", digits = 3,
        col.names = c("Store Type", "RMSLE", "Relative difference to Overall RMSLE"))
```

- Only small deviations from the overall mean are observed when broken down by store.
- Errors potentially correlated with clusters (like-stores groupings provided by Favorita) instead.

### By cluster

```{r}
rmsle_summary(1, 16, "cluster") %>% 
  select(cluster, mean_err) %>% 
  mutate(overall_compare = (mean_err - overall_rmsle) / overall_rmsle) %>% 
  arrange(mean_err) %>% 
  kable(format = "markdown", digits = 3,
        col.names = c("Store Cluster", "RMSLE", "Relative difference to Overall RMSLE"))
```

- Only slightly higher deviations from the overall RMSLE (around 6%) for the best/worst clusters compared to store type.

### By Item family

```{r}
rmsle_summary(1, 16, c("family", "perishable")) %>% 
  select(family, perishable, mean_err) %>% 
  mutate(overall_compare = (mean_err - overall_rmsle) / overall_rmsle) %>% 
  arrange(mean_err) %>% 
  kable(format = "markdown", digits = 3,
        col.names = c("Item Family", "Perishable", "RMSLE", "Relative difference to Overall RMSLE"))
```

- Books and Beauty categories very low error: potentially due to small volume of sales (a lot of 0 sales, as these items are not usually purchased at a supermarket).
- Only one perishable item in top 10, which is interesting as these data points were given a higher weight during model training.
    - Perishables (meat, fruit, vegetables) potentially subject to higher volatility and higher volumes, which model does not predict well.
    - However, most perishables still better the mean model error

### By item family - coarse groupings

```{r}
rmsle_summary(1, 16, "family_2") %>% 
  select(family_2, mean_err) %>% 
  mutate(overall_compare = (mean_err - overall_rmsle) / overall_rmsle) %>% 
  arrange(mean_err) %>% 
  kable(format = "markdown", digits = 3,
        col.names = c("Item Family - coarse grouping", "RMSLE", "Relative difference to Overall RMSLE"))
```

- Coarse groupings change ordering of best-predicted items, but the main take-away is to further investigate perishables, as these have the highest cost of error.

## Variable importance

### Variable importance by prediction day

```{r}
varimp_all %>% 
  group_by(bst) %>% 
  mutate(rn = row_number()) %>% 
  filter(rn <= 2) %>% 
  ungroup() %>% 
  mutate(bst = bst + 1) %>% 
  select(bst, day, Feature, Gain) %>% 
  kable(format = "markdown", digits = 3,
        col.names = c("Prediction period day", "Day of week", "Variable", "Gain"))
```

- Clear trends in variable importance:
    - Early in prediction period, model is dominated by mean sales in the past 1-2 weeks.
    - Later on, 2-4 weeks sales dominate.
    - However, this could just be a seasonal effect - later in the prediction period (start of August) may be more accurately predicted by sales from the start of July (which would be in the 30 day mean and not the 7-14 day mean).
- Sunday is a very seasonal day, as expected. Past 4 Sundays' sales seems quite predictive.
- Interesting points to note:
    - Shorter and longer term means (3 day, 60 day, 20 day-of-weeks) not the most prominent.

### Variable importance by variable group    
```{r}
varimp_summary_group <-
  varimp_all %>% 
    group_by(stat_group, dow_feature, data_period) %>% 
    summarise(`Mean Gain` = mean(Gain)) %>% 
    ungroup() %>%
    arrange(-`Mean Gain`) %>% 
    mutate(Cluster = Ckmeans.1d.dp::Ckmeans.1d.dp(`Mean Gain`)$cluster)

varimp_summary_group[1:15, ] %>%
  mutate(`Feature Group` = paste0(stat_group, "_", 
                                  ifelse(dow_feature == 1, "dow_", ""),
                                  data_period, "days"),
         Cluster = as.character(Cluster)) %>% 
  mutate(`Feature Group` = factor(`Feature Group`, rev(unique(`Feature Group`)))) %>% 
  ggplot(aes(x = `Feature Group`, y = `Mean Gain`, fill = Cluster, colour = Cluster)) +
  geom_bar(stat = "identity", position = "identity", width = 0.05) +
  coord_flip()
```

- Mean sales within the previous month are by far the best predictors overall. 
- Promotional information contributes little to the model.
    - This is counterintuitive as we expect promotions to drive the sales of many items. Can investigate the prevalence/distribution of promoted items in the validation period.
- 140 day averages are unnecessary; suggests that using a recent period of data is adequate to predict the next two weeks of sales.
    - (If the external environment is stable!)

## Key take-aways

- This gradient boosting setup predicts aggregate sales well using mostly mean of past sales. The simplicity of the features required and the fast training time means that the model is a good quick and dirty model to run to predict overall sales, even at the individual store level.
- However, we can investigate the following subsets of data to potentially get more accurate predictions, depending on the cost of error of each:
    - Spike sales (weekends, start of month, etc.).
    - Perishables.
    - Stores with relatively constant sales.
- We can also consider the following improvements to the current model:
    - Use predictions from earlier days of the prediction period in the training data for later days. Can help mitigate the current pattern of larger errors for later days.
    - Use multiple validation periods to tune parameters.